name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  frontend-tests:
    name: Frontend Tests (Vitest)
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run frontend tests
      run: npm run test:run
      
    - name: Generate coverage report
      run: npm run test:coverage
      
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  backend-tests:
    name: Backend Tests (Pytest)
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.11', '3.12']
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements-test.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        
    - name: Create test sample files
      working-directory: ./backend
      run: |
        mkdir -p test_data
        python -c "
import pandas as pd
data = {
    'Date': ['2024-01-01', '2024-01-02', '2024-01-03'],
    'Revenue': [1000, 1250, 980],
    'Expenses': [450, 520, 380],
    'Profit': [550, 730, 600]
}
df = pd.DataFrame(data)
df.to_excel('test_data/finance.xlsx', index=False)
df.to_csv('test_data/finance.csv', index=False)
print('Test files created')
        "
        
    - name: Run backend tests
      working-directory: ./backend
      run: |
        pytest tests/ -v --cov=services --cov-report=xml --cov-report=html
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests]
    
    services:
      # Add any required services here (e.g., databases)
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install frontend dependencies
      run: npm ci
      
    - name: Install backend dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        
    - name: Build frontend
      run: npm run build
      
    - name: Start backend server
      working-directory: ./backend
      run: |
        python run.py &
        sleep 10  # Wait for server to start
      env:
        DEBUG: false
        LOG_LEVEL: ERROR
        
    - name: Run integration tests
      working-directory: ./backend
      run: pytest tests/test_e2e.py -v -m "not slow"
      
    - name: Test MCP server
      run: |
        # Test the simple MCP server
        timeout 10s scripts/simple-mcp.bat || true
        echo "MCP server test completed"

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install security tools
      run: |
        pip install bandit safety
        
    - name: Run Bandit security scan
      working-directory: ./backend
      run: |
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . || true
        
    - name: Check for known vulnerabilities
      working-directory: ./backend
      run: |
        safety check --json --output safety-report.json || true
        safety check || true
        
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          backend/bandit-report.json
          backend/safety-report.json

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
        pip install locust
        
    - name: Run performance tests
      working-directory: ./backend
      run: |
        # Create a simple performance test
        cat > locustfile.py << 'EOF'
from locust import HttpUser, task, between

class APIUser(HttpUser):
    wait_time = between(1, 3)
    
    @task
    def health_check(self):
        self.client.get("/health")
    
    @task
    def create_file(self):
        self.client.post("/create_file", json={
            "title": "perf_test.txt",
            "content": "Performance test content"
        })
EOF
        
        # Start server in background
        python run.py &
        sleep 10
        
        # Run performance test
        locust --headless --users 10 --spawn-rate 2 --run-time 30s --host http://localhost:8000

  build-test:
    name: Build Test
    runs-on: ${{ matrix.os }}
    
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'
        
    - name: Install Rust (for Tauri)
      uses: dtolnay/rust-toolchain@stable
      
    - name: Install system dependencies (Ubuntu)
      if: matrix.os == 'ubuntu-latest'
      run: |
        sudo apt-get update
        sudo apt-get install -y libgtk-3-dev libwebkit2gtk-4.0-dev libappindicator3-dev librsvg2-dev patchelf
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build frontend
      run: npm run build
      
    - name: Build Tauri app (dev)
      run: npm run tauri build -- --debug
      env:
        TAURI_PRIVATE_KEY: ${{ secrets.TAURI_PRIVATE_KEY }}
        TAURI_KEY_PASSWORD: ${{ secrets.TAURI_KEY_PASSWORD }}

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests, integration-tests, security-tests]
    if: always()
    
    steps:
    - name: Check test results
      run: |
        echo "Frontend Tests: ${{ needs.frontend-tests.result }}"
        echo "Backend Tests: ${{ needs.backend-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Security Tests: ${{ needs.security-tests.result }}"
        
        if [[ "${{ needs.frontend-tests.result }}" == "failure" || 
              "${{ needs.backend-tests.result }}" == "failure" || 
              "${{ needs.integration-tests.result }}" == "failure" ]]; then
          echo "❌ Some tests failed"
          exit 1
        else
          echo "✅ All tests passed"
        fi